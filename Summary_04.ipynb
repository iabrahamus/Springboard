{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: 1** Write a summary of the work in this notebook. Capture the fact that you gained a baseline idea of performance by simply taking the average price and how well that did. Then highlight that you built a linear model and the features that found. Comment on the estimate of its performance from cross-validation and whether its performance on the test split was consistent with this estimate. Also highlight that a random forest regressor was tried, what preprocessing steps were found to be best, and again what its estimated performance via cross-validation was and whether its performance on the test set was consistent with that. State which model you have decided to use going forwards and why. This summary should provide a quick overview for someone wanting to know quickly why the given model was chosen for the next part of the business problem to help guide important business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook three machine learning models, namely: Average, linear regression, random forest have been used to examine and select the best model for Big Mountain Resort ticket price. We start by splitting our dataframe (ski_data) into two sets: training set ($70%$) and test set ($30%$) after extracting out the data containing our resort of interest (Big Mountain). The training set consisted of 193 rows and 36 columns while the test split is an 83 rows and 36 columns. The three columns with object data types (`Name`, `state`, and `Region`) were dropped from both splits; resulting in numerica type data splits (both train and test). \n",
    "\n",
    "\n",
    "With the train and test split data as above, we proceeded with the first simplest machine learning model, i.e., by simply setting the average price as our best guess. WE obtained $\\$63.811$ for the average price using both sklearn's DummyRegressor and by simply using the function .mean(). As expected using the average value as our prediction resulted in 0 $R^{2}$ The mean absolute error (which is the most intuitive metric) tells us that we might be off by about $\\$19$ if you guessed ticket price based on the average of known values. This is large, it is about $30%$ of the average price. Hence, we have to look for some other machine learning methods to predict our price beyond guessing it with the average.\n",
    "\n",
    "The second machine learning model employed in this notebook is a linear regression model. This model was applied on the train split while imputing missing values with median. The model resulted in an $R^{2}$ = (0.818,0.721) for (train,test) splits respectively. This means our simple linear regression model explains over $70%$ on the test and $80%$ on the train splits. The absolute mean error obtained with this model was \\$9 which is far better than \\$19 obtained using the average. Imputing missing values with mean rather the median produced similar results. The obtained lower $R^{2}$ with the test split suggests we might be overfitting with the training split. This is expected as we have used all of the features without worrying about multicollinearity in our data. To circumvent this problem we proceeded by using sklearn's `SelectKBest`, which selects the `k` best features. This method coupled with the technique called cross-validation and Hyperparameter search using GridSearchCV we find the optimal value for k to be 8. These eight best features are: `vertical_drop`, `Snow Making_ac`, `total_chairs`, `fastQuads`,`Runs`,`LongestRun_mi`, `trams`, and `SkiableTerrain_ac`. \n",
    "\n",
    "Finally, sklearn's `RandomForestRegressor` to model our ticket price. Random forest is believed to work well in a lot of cases. Fortunately, the dominant four features obtained with the Random forest are in agreement with the ones obtained with our simple linear regression model. The four top dominant features are `fastQuads`, `Runs`, `Snow Making_ac`, and `vertical_drop`. However, the random forest has an absolute error less than by ~\\$1 the linear model and exhibits less variability. Moreover, verifying on the test set performance is consistent with the cross-validation results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
